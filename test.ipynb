{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057e877d",
   "metadata": {},
   "source": [
    "# 2022 Sydney University Honours project - Novel kernels for deep learning on light field images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef404d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version:  2.9.1\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 18:53:28.518126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-15 18:53:28.598482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-15 18:53:28.598629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, glob, os, random\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import preprocessing.flatten\n",
    "import preprocessing.hci_dataset_tools.file_io as hci_io\n",
    "print('tensorflow version: ', tf.__version__)\n",
    "print('Num GPUs Available: ', len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ea76b",
   "metadata": {},
   "source": [
    "## Data Loading and Prepreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df826e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disparity file read success:  ../../datasets/hci_dataset/training/boxes/gt_disp_lowres.pfm\n",
      "disparity shape: \n",
      " (512, 512)\n",
      "depth file read success:  ../../datasets/hci_dataset/training/boxes/gt_depth_lowres.pfm\n",
      "depth shape: \n",
      " (512, 512)\n"
     ]
    }
   ],
   "source": [
    "# check disparity and depth maps\n",
    "data_path = '../../datasets'\n",
    "hci_boxes = '/hci_dataset/training/boxes/'\n",
    "\n",
    "disparity = hci_io.read_disparity(data_path + hci_boxes)\n",
    "print('disparity shape: \\n', disparity.shape)\n",
    "depth = hci_io.read_depth(data_path + hci_boxes)\n",
    "print('depth shape: \\n', depth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157d17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hci_boxes_stacked = '/hci_dataset/training/boxes/stacked/'\n",
    "\n",
    "img_shape = (7,512,7,512,3)\n",
    "\n",
    "def load_dataset(num_imgs=1, \n",
    "                 read_dirs=[data_path+hci_boxes]):\n",
    "    '''\n",
    "    load images and depth maps into tensorflow dataset (from HCI) \n",
    "    '''\n",
    "    labels = []\n",
    "    img_set = []\n",
    "    for i in range(num_imgs):\n",
    "        img = Image.open(read_dirs[i] + '/stacked/stacked.png')\n",
    "        img = np.asarray(img)\n",
    "        img = img.reshape(img_shape, order='F')\n",
    "        img_set.append(img)\n",
    "        # read depth map as labels\n",
    "        depth = hci_io.read_depth(data_path + hci_boxes)\n",
    "        labels.append(depth)\n",
    "    img_set = np.asarray(img_set)\n",
    "    labels = np.asarray(labels)\n",
    "    print(img_set.shape)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_set, labels))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e71383",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2330b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 512, 7, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset:\n",
    "    print(elem[0].numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01702f5",
   "metadata": {},
   "source": [
    "## Model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7825f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1 (Conv2D)              (None, 7, 512, 3, 255, 4  112       \n",
      "                             )                                   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 10967040)          0         \n",
      "                                                                 \n",
      " Dense (Dense)               (None, 1)                 10967041  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,967,153\n",
      "Trainable params: 10,967,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "                    keras.layers.Conv2D(input_shape=(7,512,7,512,3), filters=4, \n",
    "                                        kernel_size=3, strides=2, activation='relu', \n",
    "                                        name='Conv1'),\n",
    "                      keras.layers.Flatten(),\n",
    "                      keras.layers.Dense(1, name='Dense')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60061c93",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7074e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 7, 512, 7, 512, 3), found shape=(7, 512, 7, 512, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m               loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      5\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseCategoricalAccuracy()])\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/meme/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file5k40edeu.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/saze/anaconda3/envs/meme/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 7, 512, 7, 512, 3), found shape=(7, 512, 7, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(dataset, epochs=epochs)\n",
    "\n",
    "#test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "#print('\\nTest accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c62f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
